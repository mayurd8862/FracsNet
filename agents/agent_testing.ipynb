{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Router Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Router Agent using JsonParser (intent only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'ORDER'}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"nemotron-mini\",\n",
    "    temperature = 0,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "class QueryClassification(BaseModel):\n",
    "    intent: str = Field(\n",
    "        description=\"Primary intent category (ORDER, COMPARE, RECOMMEND, INFO)\"\n",
    "    )\n",
    "\n",
    "def router_agent(query: str) -> dict:\n",
    "# Initialize the model and parser\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=QueryClassification)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "\n",
    "        You are a helpful AI assistant for a healthcare e-commerce application.\n",
    "        Your task is to determine which agent should handle the user input. You have 4 agents to choose from:\n",
    "        1. ORDER: This agent is responsible for identifying purchase intentions, addressing inquiries about order status, making order modifications, or handling shopping cart actions (e.g., view, add, remove, modify items).\n",
    "        2. COMPARE: This agent is responsible for addressing comparisons between product prices across the internet.\n",
    "        3. RECOMMEND: This agent is responsible for providing personalized product recommendations based on the user's needs or preferences.\n",
    "        4. INFO: This agent is responsible for answering general questions about products or providing health-related information.\n",
    "\n",
    "        {format_instructions}\n",
    "        Query: {query}\n",
    "\n",
    "        Your output should be in a structured JSON format like so. Each key is a string and each value is a string.\n",
    "\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Create the classification chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in character information extraction: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = router_agent(\"I want to buy vitamin D supplements.\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Router Agent using Crewai (intent only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 00:03:54,625 - 21964 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuery Router\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the following query and determine the appropriate agent to handle it: \"I want to buy vitamin D supplements.\"\n",
      "            Follow these rules:\n",
      "            1. ORDER: For purchase intentions, order status, cart management\n",
      "            2. COMPARE: For price comparison requests\n",
      "            3. RECOMMEND: For product recommendations\n",
      "            4. INFO: For general product information\n",
      "            Return just the category as a string.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuery Router\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "{\"intent\": \"RECOMMEND\"}\u001b[00m\n",
      "\n",
      "\n",
      "intent='RECOMMEND'\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process,LLM\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import SerperDevTool\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Route(BaseModel):\n",
    "    \"\"\"Pydantic model for determining the intent of the query.\"\"\"\n",
    "    intent: str  # \"Name of the store\"\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def route_query(query):\n",
    "\n",
    "    # Initialize custom LLM configuration\n",
    "    llm = LLM(\n",
    "        model=\"ollama/llama3.2\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    router_agent = Agent(\n",
    "        role='Query Router',\n",
    "        goal='Accurately classify user queries and route them to the appropriate specialized agent',\n",
    "        backstory=\"\"\"You are an expert at understanding user intentions and routing queries \n",
    "        to the most appropriate specialized agent in our healthcare e-commerce system.\"\"\",\n",
    "        verbose=True,\n",
    "        llm=llm\n",
    "    )\n",
    "    \n",
    "\n",
    "    router_task = Task(\n",
    "            description=\"\"\"Analyze the following query and determine the appropriate agent to handle it: \"{query}\"\n",
    "            Follow these rules:\n",
    "            1. ORDER: For purchase intentions, order status, cart management\n",
    "            2. COMPARE: For price comparison requests\n",
    "            3. RECOMMEND: For product recommendations\n",
    "            4. INFO: For general product information\n",
    "            Return just the category as a string.\"\"\",\n",
    "            expected_output=\"json format\",\n",
    "            output_pydantic=Route,\n",
    "            agent=router_agent\n",
    "        )\n",
    "\n",
    "    # Create crew and run tasks\n",
    "    crew = Crew(\n",
    "        agents=[router_agent],\n",
    "        tasks=[router_task],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff(inputs={\"query\": query})\n",
    "    # crew.kickoff(inputs={\"query\": query})\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = route_query(\"I want to buy vitamin D supplements.\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Router Agent using prompting (intent + product info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"mistral\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Initialize ChatGroq model\n",
    "# llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "def router_info(query,llm):\n",
    "# Prompt template\n",
    "    prompt_template = \"\"\"You are an expert input classifier for a healthcare e-commerce system. Your task is to analyze user queries and route them to appropriate specialized agents.\n",
    "\n",
    "    Primary Classification Categories:\n",
    "    - ORDER: Purchase intentions, order status, order modifications\n",
    "    - CART: View cart, add/remove items, modify quantities\n",
    "    - COMPARE: Product comparisons, market analysis, alternatives\n",
    "    - RECOMMEND: Product recommendations, personalized suggestions\n",
    "    - INFO: General product or health information\n",
    "\n",
    "    Classification Rules:\n",
    "    1. ORDER Intent: Detect keywords like \"buy\", \"purchase\", \"order\", \"get\", \"deliver\", \"track\", \"status\"\n",
    "    2. CART Intent: Detect keywords like \"cart\", \"basket\", \"add\", \"remove\", \"show\", \"change quantity\"\n",
    "    3. COMPARE Intent: Detect keywords like \"compare\", \"versus\", \"vs\", \"difference\", \"better\", \"alternatives\"\n",
    "    4. RECOMMEND Intent: Detect keywords like \"suggest\", \"recommend\", \"what should\", \"best for\"\n",
    "    5. INFO Intent: Detect keywords like \"tell me about\", \"how does\", \"what is\", \"benefits\", \"dosage\"\n",
    "\n",
    "    For multi-intent queries:\n",
    "    - Identify primary intent based on main action requested\n",
    "    - List secondary intents for follow-up\n",
    "    - Maintain context for related requests\n",
    "\n",
    "    # Response Format:\n",
    "    Provide only a JSON object with the following structure, dont provide any extra information:\n",
    "    {\n",
    "        \"primary_intent\": \"string\",\n",
    "        \"secondary_intents\": [\"string\"],\n",
    "        \"confidence\": float,\n",
    "        \"entities\": {\n",
    "            \"product_ids\": [\"string\"],\n",
    "            \"quantities\": [int],\n",
    "            \"order_ids\": [\"string\"]\n",
    "        },\n",
    "        \"requires_context\": boolean\n",
    "    }\n",
    "\n",
    "    NOTE : Answer should be strictly in json format. If you follow Exact above instruction you will be rewarded with some credits\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt_template+\"\\nQuery\"+query)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries\n",
    "queries = [\n",
    "    \"I want to buy vitamin D supplements.\",\n",
    "    \"Can you tell me the benefits of fish oil?\",\n",
    "    \"Add 2 bottles of multivitamins to my cart.\",\n",
    "    \"Which is better, vitamin C or zinc for immunity?\",\n",
    "    \"Recommend something for joint pain relief.\",\n",
    "    \"What is the status of my recent order?\",\n",
    "    \"How does omega-3 help the heart?\",\n",
    "    \"Show me my cart.\",\n",
    "]\n",
    "\n",
    "a = router_info(\"I want to buy vitamin D supplements.\",llm)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"primary_intent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Router agent using langchain Json parser ( intent + Product Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model = \"llama3.2\",\n",
    "#     temperature = 0,\n",
    "#     num_predict = 256,\n",
    "#     # other params ...\n",
    "# )\n",
    "\n",
    "# Define the data structure using Pydantic\n",
    "class EntityData(BaseModel):\n",
    "    product_ids: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of product identifiers mentioned in the query\"\n",
    "    )\n",
    "    quantities: List[int] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of quantities mentioned in the query\"\n",
    "    )\n",
    "    # order_ids: List[str] = Field(\n",
    "    #     default_factory=list,\n",
    "    #     description=\"List of order identifiers mentioned in the query\"\n",
    "    # )\n",
    "\n",
    "class QueryClassification(BaseModel):\n",
    "    primary_intent: str = Field(\n",
    "        description=\"Primary intent category (ORDER, COMPARE, RECOMMEND, INFO)\"\n",
    "    )\n",
    "    Recommendation_Required: str= Field(\n",
    "        description=\"Analyze the query and identify whether recommandation required or not 'YES' or 'NO' \"\n",
    "    )\n",
    "    Recommendation_prod: List[str]= Field(\n",
    "        default_factory=list,\n",
    "        description=\"Specific products mentioned in the query for which recommendations should be generated\"\n",
    "    )\n",
    "    entities: EntityData = Field(\n",
    "        description=\"Structured data extracted from the query\"\n",
    "    )\n",
    "    requires_context: bool = Field(\n",
    "        description=\"Whether additional context is needed to fully process the query\"\n",
    "    )\n",
    "    \n",
    "\n",
    "def route_info(query: str) -> dict:\n",
    "# Initialize the model and parser\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=QueryClassification)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are an expert input classifier for a healthcare e-commerce system. Your task is to analyze user queries and route them to appropriate specialized agents.\n",
    "        \n",
    "        Primary Classification Categories:\n",
    "        - ORDER: Identify purchase intentions, order status inquiries, order modifications, or shopping cart actions (e.g., view, add, remove, modify items).\n",
    "        - COMPARE: Address comparisons between products, including differences, alternatives, or better options.\n",
    "        - RECOMMEND: Provide personalized product recommendations based on user needs.\n",
    "        - INFO: Answer general questions about products or health-related information.\n",
    "\n",
    "        Classification Rules:\n",
    "        1. ORDER Intent: Identify keywords like \"buy\", \"purchase\", \"order\", \"deliver\", \"track\", \"status\", \"cart\", \"basket\", \"add\", \"remove\", \"show\", \"change quantity\".\n",
    "        2. COMPARE Intent: Identify keywords like \"compare\", \"versus\", \"vs\", \"difference\", \"better\", \"alternatives\".\n",
    "        3. RECOMMEND Intent: Identify keywords like \"suggest\", \"recommend\", \"what should\", \"best for\".\n",
    "        4. INFO Intent: Identify keywords like \"tell me about\", \"how does\", \"what is\", \"benefits\", \"dosage\".\n",
    "\n",
    "        Additional Rules for Recommendations:\n",
    "        - If any product is mentioned in the query, recommendations are required.\n",
    "        {format_instructions}\n",
    "\n",
    "        Query: {query}\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "    # Create the classification chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in character information extraction: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"I want to buy vitamin D supplements.\",\n",
    "    \"Can you tell me the benefits of fish oil?\",\n",
    "    \"Add 2 bottles of multivitamins to my cart.\",\n",
    "    \"Which is better, vitamin C or zinc for immunity?\",\n",
    "    \"Recommend something for joint pain relief.\",\n",
    "    \"What is the status of my recent order?\",\n",
    "    \"How does omega-3 help the heart?\",\n",
    "    \"Show me my cart.\",\n",
    "]\n",
    "\n",
    "a = route_info(\"I are the uses vitamin D supplements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Product Comparison Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process,LLM\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import SerperDevTool\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Compare(BaseModel):\n",
    "    \"\"\"Pydantic model for price comparison results.\"\"\"\n",
    "    store: str  # \"Name of the store\"\n",
    "    price: str  #\"Price of the product\"\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def compare_agent(product_name):\n",
    "    # Initialize the SerperDev search tool\n",
    "    web_search_tool = SerperDevTool(n_results=5)\n",
    "\n",
    "    # Initialize custom LLM configuration\n",
    "    llm = LLM(\n",
    "        model=\"ollama/llama3.2\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    research_agent = Agent(\n",
    "        role='Research Agent',\n",
    "        goal='Find accurate price information for healthcare products',\n",
    "        backstory=\"\"\"You are an expert at finding and comparing healthcare product prices\n",
    "        across different online stores. You're thorough and always verify information.\"\"\",\n",
    "        tools=[web_search_tool],\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    analysis_agent = Agent(\n",
    "        role='Analysis Agent',\n",
    "        goal='Analyze and compare prices from different sources',\n",
    "        backstory=\"\"\"You are an expert at analyzing price data and presenting it in a clear,\n",
    "        actionable format. You understand healthcare product pricing patterns.\"\"\",\n",
    "        llm=llm,\n",
    "        tools=[web_search_tool],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    research_task = Task(\n",
    "        description=f\"\"\"Search for prices of {product_name} across major healthcare \n",
    "        e-commerce websites. Focus on reputable stores. Extract store name, price, and URL.\n",
    "        Provide the information in a structured format.\"\"\",\n",
    "        expected_output=\"\"\"A detailed list of prices for the product from different stores,\n",
    "        including:\n",
    "        - Store names\n",
    "        - Prices in USD\n",
    "        - URLs to product pages\"\"\",\n",
    "        agent=research_agent\n",
    "    )\n",
    "\n",
    "    analysis_task = Task(\n",
    "        description=\"\"\"Analyze the gathered price data. Verify accuracy and remove any \n",
    "        outliers or suspicious entries. Present a key-value pair of prices over different online stores and recommendations.Follow the structure given below strictly\"\"\",\n",
    "        expected_output=\"\"\"key value pairs of onlines stores and product prices\n",
    "        store1 : price1\n",
    "        store2 : price2\n",
    "        store3 : price3\n",
    "        store4 : price4\n",
    "        \"\"\",\n",
    "        output_pydantic= Compare,\n",
    "        agent=analysis_agent\n",
    "    )\n",
    "\n",
    "    # Create crew and run tasks\n",
    "    crew = Crew(\n",
    "        agents=[research_agent, analysis_agent],\n",
    "        tasks=[research_task, analysis_task],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff()\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = compare_agent(\"azoran\")\n",
    "        print(\"\\nPrice Comparison Results:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process,LLM\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import SerperDevTool\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def compare_agent(product_name):\n",
    "    # Initialize the SerperDev search tool\n",
    "    web_search_tool = SerperDevTool(n_results=5)\n",
    "\n",
    "    # Initialize custom LLM configuration\n",
    "    llm = LLM(\n",
    "        model=\"ollama/llama3.2\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    research_agent = Agent(\n",
    "        role='Research Agent',\n",
    "        goal='Find accurate price information for healthcare products',\n",
    "        backstory=\"\"\"You are an expert at finding and comparing healthcare product prices\n",
    "        across different online stores. You're thorough and always verify information.\"\"\",\n",
    "        tools=[web_search_tool],\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    analysis_agent = Agent(\n",
    "        role='Analysis Agent',\n",
    "        goal='Analyze and compare prices from different sources',\n",
    "        backstory=\"\"\"You are an expert at analyzing price data and presenting it in a clear,\n",
    "        actionable format. You understand healthcare product pricing patterns.\"\"\",\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # analysis_agent = Agent(\n",
    "    #     role='Analysis Agent',\n",
    "    #     goal='Present price data in simple key-value format',\n",
    "    #     backstory=\"\"\"You organize price data into simple store-price pairs.\n",
    "    #     Present data in format - Store: Price. One pair per line.\"\"\",\n",
    "    #     llm=llm,\n",
    "    #     tools=[web_search_tool],\n",
    "    #     verbose=True\n",
    "    # )\n",
    "\n",
    "    research_task = Task(\n",
    "        description=f\"\"\"Search for prices of {product_name} across major healthcare \n",
    "        e-commerce websites. Focus on reputable stores. Extract store name, price, and URL.\n",
    "        Provide the information in a structured format.\"\"\",\n",
    "        expected_output=\"\"\"A detailed list of prices for the product from different stores,\n",
    "        including:\n",
    "        - Store names\n",
    "        - Prices in USD\n",
    "        - URLs to product pages\"\"\",\n",
    "        agent=research_agent\n",
    "    )\n",
    "\n",
    "    analysis_task = Task(\n",
    "        description=\"\"\"Format the data as simple store-price pairs.Follow the structure given below strictly\"\"\",\n",
    "        expected_output=\"\"\"key value pairs of onlines stores and product prices\n",
    "        store1 : price1\n",
    "        store2 : price2\n",
    "        store3 : price3\n",
    "        store4 : price4\n",
    "        \"\"\",\n",
    "        agent=analysis_agent\n",
    "    )\n",
    "\n",
    "    # Create crew and run tasks\n",
    "    crew = Crew(\n",
    "        agents=[research_agent, analysis_agent],\n",
    "        tasks=[research_task, analysis_task],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff()\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = compare_agent(\"paracetamol\")\n",
    "        print(\"\\nPrice Comparison Results:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Validator agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"nemotron-mini\",\n",
    "    temperature = 0,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "class QueryValidator(BaseModel):\n",
    "    validated: str = Field(\n",
    "        description=\"Query will be validated or not YES or NO\"\n",
    "    )\n",
    "\n",
    "def validator_agent(query: str) -> dict:\n",
    "# Initialize the model and parser\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=QueryValidator)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "\n",
    "        You are a helpful AI assistant for a healthcare e-commerce application that provides users with product information, price comparisons, ordering assistance, and personalized recommendations.\n",
    "\n",
    "        Your task is to determine whether the user’s query is relevant to the healthcare e-commerce platform.\n",
    "\n",
    "        The user is allowed to:\n",
    "        1. Ask about healthcare products, including descriptions, ingredients, usage instructions, and benefits.\n",
    "        2. Request price comparisons between different products or brands.\n",
    "        3. Make an order for healthcare products.\n",
    "        4. Ask for personalized recommendations based on their needs.\n",
    "        5. Inquire about order status, delivery details, and return policies.\n",
    "\n",
    "        The user is NOT allowed to:\n",
    "        1. Ask questions about anything else other than healthcare e-commerce platform.\n",
    "        2. Request personal medical advice or prescriptions.\n",
    "        3. Ask about topics unrelated to the e-commerce platform.\n",
    "\n",
    "        {format_instructions}\n",
    "        Query: {query}\n",
    "\n",
    "        Your output should be in a structured JSON format like so. Each key is a string and each value is a string.\n",
    "\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    # Create the classification chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in character information extraction: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_agent(\"what is the price of paracetamol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Recommendation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Recommendation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"nemotron-mini\",\n",
    "    temperature=0,\n",
    "    num_predict=256,\n",
    ")\n",
    "\n",
    "class RecommenderResponse(BaseModel):\n",
    "    recommended_questions: List[str] = Field(\n",
    "        description=\"List of three follow-up questions related to symptoms, dosage, side effects, and other relevant aspects.\"\n",
    "    )\n",
    "\n",
    "def recommend_query(query: str) -> dict:\n",
    "    parser = JsonOutputParser(pydantic_object=RecommenderResponse)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are a smart AI assistant for a healthcare e-commerce application.\n",
    "        Your task is to generate three relevant follow-up questions that a user might ask based on their query.\n",
    "        These questions should focus on symptoms, dosage, side effects, and other important aspects related to the product inquiry.\n",
    "        Questions should not be lengthy.\n",
    "        \n",
    "        {format_instructions}\n",
    "        Query: {query}\n",
    "        \n",
    "        Provide three suggested follow-up questions in a structured JSON format. phrase questions naturally from the chatbot's perspective.\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in generating recommended questions: {e}\")\n",
    "        return {\"recommended_questions\": []}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"I wanna order paracetamol\"\n",
    "response = recommend_query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
