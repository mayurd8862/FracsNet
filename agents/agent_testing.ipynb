{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Router Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Router Agent using JsonParser (intent only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"deepseek-r1\",\n",
    "    temperature = 0,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "class QueryClassification(BaseModel):\n",
    "    intent: str = Field(\n",
    "        description=\"Primary intent category (ORDER, COMPARE, RECOMMEND, INFO)\"\n",
    "    )\n",
    "\n",
    "def router_agent(query: str) -> dict:\n",
    "# Initialize the model and parser\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=QueryClassification)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "\n",
    "        You are a helpful AI assistant for a healthcare e-commerce application.\n",
    "        Your task is to determine which agent should handle the user input. You have 4 agents to choose from:\n",
    "        1. ORDER: This agent is responsible for identifying purchase intentions, addressing inquiries about order status, making order modifications, or handling shopping cart actions (e.g., view, add, remove, modify items).\n",
    "        2. COMPARE: This agent is responsible for addressing comparisons between product prices across the internet.\n",
    "        3. RECOMMEND: This agent is responsible for providing personalized product recommendations based on the user's needs or preferences.\n",
    "        4. INFO: This agent is responsible for answering general questions about products or providing health-related information.\n",
    "\n",
    "        {format_instructions}\n",
    "        Query: {query}\n",
    "\n",
    "        Your output should be in a structured JSON format like so. Each key is a string and each value is a string.\n",
    "\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Create the classification chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in character information extraction: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = router_agent(\"I want to buy vitamin D supplements.\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Machine learning is a subset of artificial intelligence (AI) that involves training algorithms and models to make data-driven predictions or decisions without explicit programming. It relies on patterns in data to improve performance over time, often through techniques like supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning.\n",
      "\n",
      "### Key Concepts:\n",
      "1. **Algorithms**: Mathematical models that process data to identify patterns.\n",
      "2. **Models**: Representations of the data patterns used for predictions or decisions.\n",
      "3. **Training**: Process of feeding data into algorithms to improve model accuracy.\n",
      "4. **Features**: Input variables used by models (e.g., pixels in an image).\n",
      "5. **Labels**: Known outcomes used in supervised learning (e.g., classification tasks).\n",
      "\n",
      "### Types of Machine Learning:\n",
      "1. **Supervised Learning**: Models are trained on labeled data, where the correct output is known.\n",
      "   - Example: Email spam detection (spam vs. not spam).\n",
      "2. **Unsupervised Learning**: Models find patterns in unlabeled data without predefined outputs.\n",
      "   - Example: Customer segmentation based on purchasing behavior.\n",
      "3. **Semi-Supervised Learning**: Combines small amounts of labeled data with large amounts of unlabeled data.\n",
      "4. **Reinforcement\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"deepseek-r1\",\n",
    "    temperature = 0,\n",
    "    num_predict = 256,\n",
    ")\n",
    "\n",
    "a = llm.invoke(\"what is meant by machine learning\").content\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Router Agent using Crewai (intent only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuery Router\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the following query and determine the appropriate agent to handle it: \"I want to buy vitamin D supplements.\"\n",
      "            Follow these rules:\n",
      "            1. ORDER: For purchase intentions, order status, cart management\n",
      "            2. COMPARE: For price comparison requests\n",
      "            3. RECOMMEND: For product recommendations\n",
      "            4. INFO: For general product information\n",
      "            Return just the category as a string.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 17:03:22,103 - 14100 - __init__.py-__init__:362 - ERROR: Exception while exporting Span batch.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py\", line 174, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\util\\connection.py\", line 72, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py\", line 962, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 716, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 404, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 1061, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py\", line 363, in connect\n",
      "    self.sock = conn = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connection.py\", line 186, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000002104FDA3FD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\connectionpool.py\", line 802, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\util\\retry.py\", line 594, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002104FDA3FD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\opentelemetry\\sdk\\trace\\export\\__init__.py\", line 360, in _export_batch\n",
      "    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\http\\trace_exporter\\__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\http\\trace_exporter\\__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\http\\trace_exporter\\__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\adapters.py\", line 700, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002104FDA3FD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process,LLM\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import SerperDevTool\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Route(BaseModel):\n",
    "    \"\"\"Pydantic model for determining the intent of the query.\"\"\"\n",
    "    intent: str  # \"Name of the store\"\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def route_query(query):\n",
    "\n",
    "    # Initialize custom LLM configuration\n",
    "    llm = LLM(\n",
    "        model=\"ollama/llama3.2\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    router_agent = Agent(\n",
    "        role='Query Router',\n",
    "        goal='Accurately classify user queries and route them to the appropriate specialized agent',\n",
    "        backstory=\"\"\"You are an expert at understanding user intentions and routing queries \n",
    "        to the most appropriate specialized agent in our healthcare e-commerce system.\"\"\",\n",
    "        verbose=True,\n",
    "        llm=llm\n",
    "    )\n",
    "    \n",
    "\n",
    "    router_task = Task(\n",
    "            description=\"\"\"Analyze the following query and determine the appropriate agent to handle it: \"{query}\"\n",
    "            Follow these rules:\n",
    "            1. ORDER: For purchase intentions, order status, cart management\n",
    "            2. COMPARE: For price comparison requests\n",
    "            3. RECOMMEND: For product recommendations\n",
    "            4. INFO: For general product information\n",
    "            Return just the category as a string.\"\"\",\n",
    "            expected_output=\"json format\",\n",
    "            output_pydantic=Route,\n",
    "            agent=router_agent\n",
    "        )\n",
    "\n",
    "    # Create crew and run tasks\n",
    "    crew = Crew(\n",
    "        agents=[router_agent],\n",
    "        tasks=[router_task],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff(inputs={\"query\": query})\n",
    "    # crew.kickoff(inputs={\"query\": query})\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = route_query(\"I want to buy vitamin D supplements.\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Router Agent using prompting (intent + product info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"mistral\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Initialize ChatGroq model\n",
    "# llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "def router_info(query,llm):\n",
    "# Prompt template\n",
    "    prompt_template = \"\"\"You are an expert input classifier for a healthcare e-commerce system. Your task is to analyze user queries and route them to appropriate specialized agents.\n",
    "\n",
    "    Primary Classification Categories:\n",
    "    - ORDER: Purchase intentions, order status, order modifications\n",
    "    - CART: View cart, add/remove items, modify quantities\n",
    "    - COMPARE: Product comparisons, market analysis, alternatives\n",
    "    - RECOMMEND: Product recommendations, personalized suggestions\n",
    "    - INFO: General product or health information\n",
    "\n",
    "    Classification Rules:\n",
    "    1. ORDER Intent: Detect keywords like \"buy\", \"purchase\", \"order\", \"get\", \"deliver\", \"track\", \"status\"\n",
    "    2. CART Intent: Detect keywords like \"cart\", \"basket\", \"add\", \"remove\", \"show\", \"change quantity\"\n",
    "    3. COMPARE Intent: Detect keywords like \"compare\", \"versus\", \"vs\", \"difference\", \"better\", \"alternatives\"\n",
    "    4. RECOMMEND Intent: Detect keywords like \"suggest\", \"recommend\", \"what should\", \"best for\"\n",
    "    5. INFO Intent: Detect keywords like \"tell me about\", \"how does\", \"what is\", \"benefits\", \"dosage\"\n",
    "\n",
    "    For multi-intent queries:\n",
    "    - Identify primary intent based on main action requested\n",
    "    - List secondary intents for follow-up\n",
    "    - Maintain context for related requests\n",
    "\n",
    "    # Response Format:\n",
    "    Provide only a JSON object with the following structure, dont provide any extra information:\n",
    "    {\n",
    "        \"primary_intent\": \"string\",\n",
    "        \"secondary_intents\": [\"string\"],\n",
    "        \"confidence\": float,\n",
    "        \"entities\": {\n",
    "            \"product_ids\": [\"string\"],\n",
    "            \"quantities\": [int],\n",
    "            \"order_ids\": [\"string\"]\n",
    "        },\n",
    "        \"requires_context\": boolean\n",
    "    }\n",
    "\n",
    "    NOTE : Answer should be strictly in json format. If you follow Exact above instruction you will be rewarded with some credits\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt_template+\"\\nQuery\"+query)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries\n",
    "queries = [\n",
    "    \"I want to buy vitamin D supplements.\",\n",
    "    \"Can you tell me the benefits of fish oil?\",\n",
    "    \"Add 2 bottles of multivitamins to my cart.\",\n",
    "    \"Which is better, vitamin C or zinc for immunity?\",\n",
    "    \"Recommend something for joint pain relief.\",\n",
    "    \"What is the status of my recent order?\",\n",
    "    \"How does omega-3 help the heart?\",\n",
    "    \"Show me my cart.\",\n",
    "]\n",
    "\n",
    "a = router_info(\"I want to buy vitamin D supplements.\",llm)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"primary_intent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Router agent using langchain Json parser ( intent + Product Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model = \"llama3.2\",\n",
    "#     temperature = 0,\n",
    "#     num_predict = 256,\n",
    "#     # other params ...\n",
    "# )\n",
    "\n",
    "# Define the data structure using Pydantic\n",
    "class EntityData(BaseModel):\n",
    "    product_ids: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of product identifiers mentioned in the query\"\n",
    "    )\n",
    "    quantities: List[int] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of quantities mentioned in the query\"\n",
    "    )\n",
    "    # order_ids: List[str] = Field(\n",
    "    #     default_factory=list,\n",
    "    #     description=\"List of order identifiers mentioned in the query\"\n",
    "    # )\n",
    "\n",
    "class QueryClassification(BaseModel):\n",
    "    primary_intent: str = Field(\n",
    "        description=\"Primary intent category (ORDER, COMPARE, RECOMMEND, INFO)\"\n",
    "    )\n",
    "    Recommendation_Required: str= Field(\n",
    "        description=\"Analyze the query and identify whether recommandation required or not 'YES' or 'NO' \"\n",
    "    )\n",
    "    Recommendation_prod: List[str]= Field(\n",
    "        default_factory=list,\n",
    "        description=\"Specific products mentioned in the query for which recommendations should be generated\"\n",
    "    )\n",
    "    entities: EntityData = Field(\n",
    "        description=\"Structured data extracted from the query\"\n",
    "    )\n",
    "    requires_context: bool = Field(\n",
    "        description=\"Whether additional context is needed to fully process the query\"\n",
    "    )\n",
    "    \n",
    "\n",
    "def route_info(query: str) -> dict:\n",
    "# Initialize the model and parser\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=QueryClassification)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are an expert input classifier for a healthcare e-commerce system. Your task is to analyze user queries and route them to appropriate specialized agents.\n",
    "        \n",
    "        Primary Classification Categories:\n",
    "        - ORDER: Identify purchase intentions, order status inquiries, order modifications, or shopping cart actions (e.g., view, add, remove, modify items).\n",
    "        - COMPARE: Address comparisons between products, including differences, alternatives, or better options.\n",
    "        - RECOMMEND: Provide personalized product recommendations based on user needs.\n",
    "        - INFO: Answer general questions about products or health-related information.\n",
    "\n",
    "        Classification Rules:\n",
    "        1. ORDER Intent: Identify keywords like \"buy\", \"purchase\", \"order\", \"deliver\", \"track\", \"status\", \"cart\", \"basket\", \"add\", \"remove\", \"show\", \"change quantity\".\n",
    "        2. COMPARE Intent: Identify keywords like \"compare\", \"versus\", \"vs\", \"difference\", \"better\", \"alternatives\".\n",
    "        3. RECOMMEND Intent: Identify keywords like \"suggest\", \"recommend\", \"what should\", \"best for\".\n",
    "        4. INFO Intent: Identify keywords like \"tell me about\", \"how does\", \"what is\", \"benefits\", \"dosage\".\n",
    "\n",
    "        Additional Rules for Recommendations:\n",
    "        - If any product is mentioned in the query, recommendations are required.\n",
    "        {format_instructions}\n",
    "\n",
    "        Query: {query}\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "    # Create the classification chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in character information extraction: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"I want to buy vitamin D supplements.\",\n",
    "    \"Can you tell me the benefits of fish oil?\",\n",
    "    \"Add 2 bottles of multivitamins to my cart.\",\n",
    "    \"Which is better, vitamin C or zinc for immunity?\",\n",
    "    \"Recommend something for joint pain relief.\",\n",
    "    \"What is the status of my recent order?\",\n",
    "    \"How does omega-3 help the heart?\",\n",
    "    \"Show me my cart.\",\n",
    "]\n",
    "\n",
    "a = route_info(\"I are the uses vitamin D supplements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Product Comparison Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process,LLM\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import SerperDevTool\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Compare(BaseModel):\n",
    "    \"\"\"Pydantic model for price comparison results.\"\"\"\n",
    "    store: str  # \"Name of the store\"\n",
    "    price: str  #\"Price of the product\"\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def compare_agent(product_name):\n",
    "    # Initialize the SerperDev search tool\n",
    "    web_search_tool = SerperDevTool(n_results=5)\n",
    "\n",
    "    # Initialize custom LLM configuration\n",
    "    llm = LLM(\n",
    "        model=\"ollama/llama3.2\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    research_agent = Agent(\n",
    "        role='Research Agent',\n",
    "        goal='Find accurate price information for healthcare products',\n",
    "        backstory=\"\"\"You are an expert at finding and comparing healthcare product prices\n",
    "        across different online stores. You're thorough and always verify information.\"\"\",\n",
    "        tools=[web_search_tool],\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    analysis_agent = Agent(\n",
    "        role='Analysis Agent',\n",
    "        goal='Analyze and compare prices from different sources',\n",
    "        backstory=\"\"\"You are an expert at analyzing price data and presenting it in a clear,\n",
    "        actionable format. You understand healthcare product pricing patterns.\"\"\",\n",
    "        llm=llm,\n",
    "        tools=[web_search_tool],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    research_task = Task(\n",
    "        description=f\"\"\"Search for prices of {product_name} across major healthcare \n",
    "        e-commerce websites. Focus on reputable stores. Extract store name, price, and URL.\n",
    "        Provide the information in a structured format.\"\"\",\n",
    "        expected_output=\"\"\"A detailed list of prices for the product from different stores,\n",
    "        including:\n",
    "        - Store names\n",
    "        - Prices in USD\n",
    "        - URLs to product pages\"\"\",\n",
    "        agent=research_agent\n",
    "    )\n",
    "\n",
    "    analysis_task = Task(\n",
    "        description=\"\"\"Analyze the gathered price data. Verify accuracy and remove any \n",
    "        outliers or suspicious entries. Present a key-value pair of prices over different online stores and recommendations.Follow the structure given below strictly\"\"\",\n",
    "        expected_output=\"\"\"key value pairs of onlines stores and product prices\n",
    "        store1 : price1\n",
    "        store2 : price2\n",
    "        store3 : price3\n",
    "        store4 : price4\n",
    "        \"\"\",\n",
    "        output_pydantic= Compare,\n",
    "        agent=analysis_agent\n",
    "    )\n",
    "\n",
    "    # Create crew and run tasks\n",
    "    crew = Crew(\n",
    "        agents=[research_agent, analysis_agent],\n",
    "        tasks=[research_task, analysis_task],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff()\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = compare_agent(\"azoran\")\n",
    "        print(\"\\nPrice Comparison Results:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process,LLM\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import SerperDevTool\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def compare_agent(product_name):\n",
    "    # Initialize the SerperDev search tool\n",
    "    web_search_tool = SerperDevTool(n_results=5)\n",
    "\n",
    "    # Initialize custom LLM configuration\n",
    "    llm = LLM(\n",
    "        model=\"ollama/llama3.2\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    research_agent = Agent(\n",
    "        role='Research Agent',\n",
    "        goal='Find accurate price information for healthcare products',\n",
    "        backstory=\"\"\"You are an expert at finding and comparing healthcare product prices\n",
    "        across different online stores. You're thorough and always verify information.\"\"\",\n",
    "        tools=[web_search_tool],\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    analysis_agent = Agent(\n",
    "        role='Analysis Agent',\n",
    "        goal='Analyze and compare prices from different sources',\n",
    "        backstory=\"\"\"You are an expert at analyzing price data and presenting it in a clear,\n",
    "        actionable format. You understand healthcare product pricing patterns.\"\"\",\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # analysis_agent = Agent(\n",
    "    #     role='Analysis Agent',\n",
    "    #     goal='Present price data in simple key-value format',\n",
    "    #     backstory=\"\"\"You organize price data into simple store-price pairs.\n",
    "    #     Present data in format - Store: Price. One pair per line.\"\"\",\n",
    "    #     llm=llm,\n",
    "    #     tools=[web_search_tool],\n",
    "    #     verbose=True\n",
    "    # )\n",
    "\n",
    "    research_task = Task(\n",
    "        description=f\"\"\"Search for prices of {product_name} across major healthcare \n",
    "        e-commerce websites. Focus on reputable stores. Extract store name, price, and URL.\n",
    "        Provide the information in a structured format.\"\"\",\n",
    "        expected_output=\"\"\"A detailed list of prices for the product from different stores,\n",
    "        including:\n",
    "        - Store names\n",
    "        - Prices in USD\n",
    "        - URLs to product pages\"\"\",\n",
    "        agent=research_agent\n",
    "    )\n",
    "\n",
    "    analysis_task = Task(\n",
    "        description=\"\"\"Format the data as simple store-price pairs.Follow the structure given below strictly\"\"\",\n",
    "        expected_output=\"\"\"key value pairs of onlines stores and product prices\n",
    "        store1 : price1\n",
    "        store2 : price2\n",
    "        store3 : price3\n",
    "        store4 : price4\n",
    "        \"\"\",\n",
    "        agent=analysis_agent\n",
    "    )\n",
    "\n",
    "    # Create crew and run tasks\n",
    "    crew = Crew(\n",
    "        agents=[research_agent, analysis_agent],\n",
    "        tasks=[research_task, analysis_task],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff()\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = compare_agent(\"paracetamol\")\n",
    "        print(\"\\nPrice Comparison Results:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Validator agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"nemotron-mini\",\n",
    "    temperature = 0,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "class QueryValidator(BaseModel):\n",
    "    validated: str = Field(\n",
    "        description=\"Query will be validated or not YES or NO\"\n",
    "    )\n",
    "\n",
    "def validator_agent(query: str) -> dict:\n",
    "# Initialize the model and parser\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=QueryValidator)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "\n",
    "        You are a helpful AI assistant for a healthcare e-commerce application that provides users with product information, price comparisons, ordering assistance, and personalized recommendations.\n",
    "\n",
    "        Your task is to determine whether the user’s query is relevant to the healthcare e-commerce platform.\n",
    "\n",
    "        The user is allowed to:\n",
    "        1. Ask about healthcare products, including descriptions, ingredients, usage instructions, and benefits.\n",
    "        2. Request price comparisons between different products or brands.\n",
    "        3. Make an order for healthcare products.\n",
    "        4. Ask for personalized recommendations based on their needs.\n",
    "        5. Inquire about order status, delivery details, and return policies.\n",
    "\n",
    "        The user is NOT allowed to:\n",
    "        1. Ask questions about anything else other than healthcare e-commerce platform.\n",
    "        2. Request personal medical advice or prescriptions.\n",
    "        3. Ask about topics unrelated to the e-commerce platform.\n",
    "\n",
    "        {format_instructions}\n",
    "        Query: {query}\n",
    "\n",
    "        Your output should be in a structured JSON format like so. Each key is a string and each value is a string.\n",
    "\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    # Create the classification chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in character information extraction: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_agent(\"what is the price of paracetamol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Recommendation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Recommendation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"nemotron-mini\",\n",
    "    temperature=0,\n",
    "    num_predict=256,\n",
    ")\n",
    "\n",
    "class RecommenderResponse(BaseModel):\n",
    "    recommended_questions: List[str] = Field(\n",
    "        description=\"List of three follow-up questions related to symptoms, dosage, side effects, and other relevant aspects.\"\n",
    "    )\n",
    "\n",
    "def recommend_query(query: str) -> dict:\n",
    "    parser = JsonOutputParser(pydantic_object=RecommenderResponse)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are a smart AI assistant for a healthcare e-commerce application.\n",
    "        Your task is to generate three relevant follow-up questions that a user might ask based on their query.\n",
    "        These questions should focus on symptoms, dosage, side effects, and other important aspects related to the product inquiry.\n",
    "        Questions should not be lengthy.\n",
    "        \n",
    "        {format_instructions}\n",
    "        Query: {query}\n",
    "        \n",
    "        Provide three suggested follow-up questions in a structured JSON format. phrase questions naturally from the chatbot's perspective.\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in generating recommended questions: {e}\")\n",
    "        return {\"recommended_questions\": []}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"I wanna order paracetamol\"\n",
    "response = recommend_query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
